{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM,Embedding,Linear\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class compare_regex(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n",
    "        super(compare_regex, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n",
    "        self.fc1 = Linear(hidden_dim*2*2, 60)\n",
    "        self.fc2 = Linear(60, 20)\n",
    "        self.fc3 = Linear(20, target_size)\n",
    "\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        if torch.cuda.is_available():\n",
    "            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n",
    "                   torch.zeros(2, bs, self.hidden_dim).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(2, bs, self.hidden_dim),\n",
    "                   torch.zeros(2, bs, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, bs, line1, line2, input1_lengths,input2_lengths):\n",
    "        embeded1 = self.embed(line1)\n",
    "        embeded2 = self.embed(line2)\n",
    "#         packed1 = torch.nn.utils.rnn.pack_padded_sequence(embeded1, input1_lengths, batch_first=True)\n",
    "#         packed2 = torch.nn.utils.rnn.pack_padded_sequence(embeded2, input2_lengths, batch_first=True)\n",
    "        hidden1 = self.init_hidden(bs)\n",
    "        lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n",
    "        hidden2 = self.init_hidden(bs)\n",
    "        lstm2_out, last_hidden2 = self.lstm2(embeded2,hidden2)\n",
    "#         unpack1, unpack1_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm1_out, batch_first=True)\n",
    "#         unpack2, unpack2_lengths = torch.nn.utils.rnn.pad_packed_sequence(lstm2_out, batch_first=True)\n",
    "\n",
    "#         lstm1_last_hidden = (torch.gather(lstm1_out,1,torch.tensor(input1_lengths).cuda().expand(self.hidden_dim, 1,-1).transpose(0,2)-1)).cuda()\n",
    "#         lstm2_last_hidden = (torch.gather(lstm2_out,1,torch.tensor(input2_lengths).cuda().expand(self.hidden_dim, 1,-1).transpose(0,2)-1)).cuda()\n",
    "\n",
    "\n",
    "        fc1_out = self.fc1(torch.cat((lstm1_out.mean(1), lstm2_out.mean(1)),1))  #encoder outputs 평균값 concat 97.8%\n",
    "#         fc1_out = self.fc1(lstm1_out.mean(1) * lstm2_out.mean(1))              #encoder outputs 평균값 multiple\n",
    "#         fc1_out = self.fc1(torch.cat((lstm1_last_hidden.squeeze(1),lstm2_last_hidden.squeeze(1)), 1))     #last hidden concat 97.1%\n",
    "#         fc1_out = self.fc1(lstm1_last_hidden.squeeze(1) * lstm2_last_hidden.squeeze(1))     #last hidden multiple\n",
    "\n",
    "        \n",
    "        fc1_out = F.tanh(fc1_out)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        fc2_out = F.tanh(fc2_out)\n",
    "        fc3_out = self.fc3(fc2_out)\n",
    "        score = F.log_softmax(fc3_out,dim=1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "f = open('./compare_vocab.txt','r')\n",
    "for i in f.read().splitlines():\n",
    "    splitted = i.split('\\t')\n",
    "    vocab[splitted[0]] = int(splitted[1])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_seq(lines1, lines2, targets):\n",
    "    max_len = 40\n",
    "    lines1_seq2idx = list()\n",
    "    lines2_seq2idx = list()\n",
    "    targets_idx = list()\n",
    "    lines1_seq = [s.split() for s in lines1]\n",
    "    lines2_seq = [s.split() for s in lines2]\n",
    "    for line_num in range(len(lines1_seq)):\n",
    "        if len(lines1_seq[line_num]) > max_len or len(lines2_seq[line_num]) > max_len:\n",
    "            continue\n",
    "        lines1_padded = lines1_seq[line_num]+['<pad>']*(max_len-len(lines1_seq[line_num]))\n",
    "        lines2_padded = lines2_seq[line_num]+['<pad>']*(max_len-len(lines2_seq[line_num]))\n",
    "        lines1_seq2idx.append([vocab[i] for i in lines1_padded])\n",
    "        lines2_seq2idx.append([vocab[i] for i in lines2_padded])\n",
    "        \n",
    "        if targets[line_num] == '0':\n",
    "            targets_idx.append([1,0])\n",
    "        else:\n",
    "            targets_idx.append([0,1])\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.LongTensor(lines1_seq2idx).cuda(), torch.LongTensor(lines2_seq2idx).cuda(), torch.LongTensor(targets_idx).cuda()\n",
    "    else:\n",
    "        return torch.LongTensor(lines1_seq2idx), torch.LongTensor(lines2_seq2idx), torch.LongTensor(targets_idx)\n",
    "        \n",
    "def evaluate_test(model, test_input1, test_input2 , test_target):\n",
    "    correct = 0\n",
    "    print(len(test_target))\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    count=0\n",
    "    for i in range(len(test_input1)):\n",
    "        count+=1\n",
    "        test_input1_len = torch.tensor([torch.max(test_input1[i].data.nonzero()+1)])\n",
    "        test_input2_len = torch.tensor([torch.max(test_input2[i].data.nonzero()+1)])\n",
    "        score = model(1, test_input1[i].unsqueeze(0), test_input2[i].unsqueeze(0) , test_input1_len.tolist(), test_input2_len.tolist())\n",
    "        if score.argmax().item() == 1 and test_target[i].argmax().item()==1:\n",
    "            tp+=1\n",
    "        elif score.argmax().item() == 0 and test_target[i].argmax().item()==0:\n",
    "            tn+=1\n",
    "        elif score.argmax().item() == 1 and test_target[i].argmax().item()==0:\n",
    "            fp+=1\n",
    "        elif score.argmax().item() == 0 and test_target[i].argmax().item()==1:\n",
    "            fn+=1\n",
    "        if score.argmax().item() == test_target[i].argmax().item():\n",
    "            correct += 1\n",
    "    precision =  tp/(tp+fp)\n",
    "    recall =  tp/(tp+fn)\n",
    "    f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    print('precision: {},recall: {},f1 score:{}'.format(precision,recall,f1_score))\n",
    "    print('total: {}, correct: {}'.format(len(test_target), correct))\n",
    "    return correct/len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_regex_model = torch.load('./compare_regex_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('../pair_data/test_data.txt','r')\n",
    "f = open('../pair_data/data_pairs_test(4_depth).txt','r')\n",
    "# f = open('../pair_data/data_pairs_test(5_depth).txt','r')\n",
    "\n",
    "\n",
    "total_set = set()\n",
    "lines1 = list()\n",
    "lines2 = list()\n",
    "targets = list()\n",
    "\n",
    "# count = 0\n",
    "# for line in f.read().splitlines():\n",
    "#     count += 1\n",
    "#     total_set.add(line)\n",
    "#     splitted = line.split('\\t')\n",
    "# print(count)\n",
    "\n",
    "count = 0\n",
    "for line in f.read().splitlines():\n",
    "    count += 1\n",
    "    splitted = line.split('\\t')\n",
    "    lines1.append(splitted[0])\n",
    "    lines2.append(splitted[1])\n",
    "    targets.append(splitted[2])\n",
    "\n",
    "test_input1, test_input2, test_targets = make_input_seq(lines1, lines2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        print('test acc: {}'.format(evaluate_test(compare_regex_model, test_input1, test_input2,  test_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
