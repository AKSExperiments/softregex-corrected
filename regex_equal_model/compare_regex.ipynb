{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LSTM,Embedding,Linear\n",
    "from torch.nn import Module\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class compare_regex(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, target_size):\n",
    "        super(compare_regex, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embed = Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm1 = LSTM(embedding_dim ,hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = LSTM(embedding_dim, hidden_dim, bidirectional=True, num_layers=1, batch_first=True)\n",
    "        self.fc1 = Linear(hidden_dim*2*2, 60)\n",
    "        self.fc2 = Linear(60, 20)\n",
    "        self.fc3 = Linear(20, target_size)\n",
    "\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        if torch.cuda.is_available():\n",
    "            return (torch.zeros(2, bs, self.hidden_dim).cuda(),\n",
    "                   torch.zeros(2, bs, self.hidden_dim).cuda())\n",
    "        else:\n",
    "            return (torch.zeros(2, bs, self.hidden_dim),\n",
    "                   torch.zeros(2, bs, self.hidden_dim))\n",
    "    \n",
    "    def forward(self, bs, line1, line2, input1_lengths,input2_lengths):\n",
    "        embeded1 = self.embed(line1)\n",
    "        embeded2 = self.embed(line2)\n",
    "        hidden1 = self.init_hidden(bs)\n",
    "        lstm1_out, last_hidden1 = self.lstm1(embeded1,hidden1)\n",
    "        hidden2 = self.init_hidden(bs)\n",
    "        lstm2_out, last_hidden2 = self.lstm1(embeded2,hidden2)\n",
    "        fc1_out = self.fc1(torch.cat((lstm1_out.mean(1), lstm2_out.mean(1)),1))\n",
    "\n",
    "        fc1_out = F.tanh(fc1_out)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        fc2_out = F.tanh(fc2_out)\n",
    "        fc3_out = self.fc3(fc2_out)\n",
    "        score = F.log_softmax(fc3_out,dim=1)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../pair_data/train_data.txt','r')\n",
    "\n",
    "total_set = set()\n",
    "lines1 = list()\n",
    "lines2 = list()\n",
    "targets = list()\n",
    "\n",
    "\n",
    "for line in f.read().splitlines():\n",
    "    splitted = line.split('\\t')\n",
    "    a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n",
    "    if not a in total_set:\n",
    "        total_set.add(line)\n",
    "        \n",
    "train_lines1 = list()\n",
    "train_lines2 = list()\n",
    "train_targets = list()\n",
    "for line in total_set:\n",
    "    splitted = line.split('\\t')\n",
    "    train_lines1.append(splitted[0])\n",
    "    train_lines2.append(splitted[1])\n",
    "    train_targets.append(splitted[2])\n",
    "    train_lines1.append(splitted[1])\n",
    "    train_lines2.append(splitted[0])\n",
    "    train_targets.append(splitted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../pair_data/test_data.txt','r')\n",
    "\n",
    "total_set = set()\n",
    "lines1 = list()\n",
    "lines2 = list()\n",
    "targets = list()\n",
    "\n",
    "\n",
    "for line in f.read().splitlines():\n",
    "    splitted = line.split('\\t')\n",
    "    a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n",
    "    if not a in total_set:\n",
    "        total_set.add(line)\n",
    "        \n",
    "test_lines1 = list()\n",
    "test_lines2 = list()\n",
    "test_targets = list()\n",
    "for line in total_set:\n",
    "    splitted = line.split('\\t')\n",
    "    test_lines1.append(splitted[0])\n",
    "    test_lines2.append(splitted[1])\n",
    "    test_targets.append(splitted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete cell\n",
    "f = open('../pair_data/data_pairs_test(4_depth).txt','r')\n",
    "# f = open('../pair_data/test_data.txt','r')\n",
    "\n",
    "total_set = set()\n",
    "lines1 = list()\n",
    "lines2 = list()\n",
    "targets = list()\n",
    "\n",
    "\n",
    "for line in f.read().splitlines():\n",
    "    splitted = line.split('\\t')\n",
    "    a = '{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2])\n",
    "    if not a in total_set:\n",
    "        total_set.add(line)\n",
    "        \n",
    "test_lines1 = list()\n",
    "test_lines2 = list()\n",
    "test_targets = list()\n",
    "for line in total_set:\n",
    "    splitted = line.split('\\t')\n",
    "    test_lines1.append(splitted[0])\n",
    "    test_lines2.append(splitted[1])\n",
    "    test_targets.append(splitted[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372728\n",
      "995\n"
     ]
    }
   ],
   "source": [
    "print(len(train_lines1))\n",
    "print(len(test_lines1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "vocab = {w:i for i,w in enumerate(set([t for s in train_lines1 for t in s.split(' ')]), 1)}\n",
    "vocab['<pad>'] = 0\n",
    "vocab_size = len(vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 30, '6': 2, '4': 16, '<pad>': 0, '<CAP>': 3, ',': 17, '.': 4, '2': 5, '3': 28, '<M2>': 6, ']': 8, '~': 19, '<M3>': 20, '+': 21, '<NUM>': 22, ')': 7, '\\\\': 9, '}': 1, '&': 23, '<LOW>': 24, '(': 25, '<M0>': 26, '<M1>': 10, '{': 11, '*': 29, '7': 12, '[': 13, '5': 15, '|': 14, '<LET>': 18, '<VOW>': 27}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_w = open('./compare_vocab(uncleaned).txt','w')\n",
    "# for i in vocab.items():\n",
    "#     f_w.write('{}\\t{}\\n'.format(i[0],i[1]))\n",
    "# f_w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "f = open('./compare_vocab.txt','r')\n",
    "for i in f.read().splitlines():\n",
    "    splitted = i.split('\\t')\n",
    "    vocab[splitted[0]] = int(splitted[1])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def make_input_seq(lines1, lines2, targets):\n",
    "    max_len = 40\n",
    "    lines1_seq2idx = list()\n",
    "    lines2_seq2idx = list()\n",
    "    targets_idx = list()\n",
    "    lines1_seq = [s.split() for s in lines1]\n",
    "    lines2_seq = [s.split() for s in lines2]\n",
    "    for line_num in range(len(lines1_seq)):\n",
    "        if len(lines1_seq[line_num]) > max_len or len(lines2_seq[line_num]) > max_len:\n",
    "            continue\n",
    "        lines1_padded = lines1_seq[line_num]+['<pad>']*(max_len-len(lines1_seq[line_num]))\n",
    "        lines2_padded = lines2_seq[line_num]+['<pad>']*(max_len-len(lines2_seq[line_num]))\n",
    "        lines1_seq2idx.append([vocab[i] for i in lines1_padded])\n",
    "        lines2_seq2idx.append([vocab[i] for i in lines2_padded])\n",
    "        \n",
    "        if targets[line_num] == '0':\n",
    "            targets_idx.append([1,0])\n",
    "        else:\n",
    "            targets_idx.append([0,1])\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.LongTensor(lines1_seq2idx).cuda(), torch.LongTensor(lines2_seq2idx).cuda(), torch.LongTensor(targets_idx).cuda()\n",
    "    else:\n",
    "        return torch.LongTensor(lines1_seq2idx), torch.LongTensor(lines2_seq2idx), torch.LongTensor(targets_idx)\n",
    "        \n",
    "\n",
    "\n",
    "lines1_seq2idx, lines2_seq2idx, targets_idx = make_input_seq(train_lines1, train_lines2, train_targets)\n",
    "test_input1, test_input2, test_targets = make_input_seq(test_lines1, test_lines2, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372728\n",
      "372728\n",
      "995\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(lines1_seq2idx))\n",
    "print(len(lines2_seq2idx))\n",
    "print(len(test_targets))\n",
    "print(test_targets.tolist().count([1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_test(model, test_input1, test_input2 , test_target):\n",
    "    correct = 0\n",
    "    print(len(test_target))\n",
    "    tp=0\n",
    "    tn=0\n",
    "    fp=0\n",
    "    fn=0\n",
    "    for i in range(len(test_input1)):\n",
    "        test_input1_len = torch.tensor([torch.max(test_input1[i].data.nonzero()+1)])\n",
    "        test_input2_len = torch.tensor([torch.max(test_input2[i].data.nonzero()+1)])\n",
    "        score = model(1, test_input1[i].unsqueeze(0), test_input2[i].unsqueeze(0) , test_input1_len.tolist(), test_input2_len.tolist())\n",
    "        if score.argmax().item() == 1 and test_target[i].argmax().item()==1:\n",
    "            tp+=1\n",
    "        elif score.argmax().item() == 0 and test_target[i].argmax().item()==0:\n",
    "            tn+=1\n",
    "        elif score.argmax().item() == 1 and test_target[i].argmax().item()==0:\n",
    "            fp+=1\n",
    "        elif score.argmax().item() == 0 and test_target[i].argmax().item()==1:\n",
    "            fn+=1\n",
    "        if score.argmax().item() == test_target[i].argmax().item():\n",
    "            correct += 1\n",
    "    try:\n",
    "        precision =  tp/(tp+fp)\n",
    "        recall =  tp/(tp+fn)\n",
    "        f1_score = 2*((precision*recall)/(precision+recall))\n",
    "    except:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        f1_score = 0\n",
    "    print('precision: {},recall: {},f1 score:{}'.format(precision,recall,f1_score))\n",
    "    print('total: {}, correct: {}'.format(len(test_target), correct))\n",
    "    return correct/len(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    compare_regex_model = compare_regex(vocab_size, 4, 256, 2).cuda()\n",
    "else:\n",
    "    compare_regex_model = compare_regex(vocab_size, 4, 256, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995\n",
      "precision: 0,recall: 0,f1 score:0\n",
      "total: 995, correct: 500\n",
      "step:0, test acc: 0.5025125628140703\n",
      "epoch: 0, epoch_loss: 0.6588908670284495\n",
      "epoch: 1, epoch_loss: 0.6581749831687953\n",
      "epoch: 2, epoch_loss: 0.6572307682938592\n",
      "epoch: 3, epoch_loss: 0.6564091485390549\n",
      "epoch: 4, epoch_loss: 0.6554413310031301\n",
      "epoch: 5, epoch_loss: 0.6540630036203312\n",
      "epoch: 6, epoch_loss: 0.6524990326350497\n",
      "epoch: 7, epoch_loss: 0.6509233166262046\n",
      "epoch: 8, epoch_loss: 0.6493500121680322\n",
      "epoch: 9, epoch_loss: 0.6478368613728134\n",
      "995\n",
      "precision: 0.8584070796460177,recall: 0.19595959595959597,f1 score:0.3190789473684211\n",
      "total: 995, correct: 581\n",
      "step:10, test acc: 0.5839195979899497\n",
      "epoch: 10, epoch_loss: 0.6464455692219161\n",
      "epoch: 11, epoch_loss: 0.6452107792048111\n",
      "epoch: 12, epoch_loss: 0.6441339616513334\n",
      "epoch: 13, epoch_loss: 0.6431965768132423\n",
      "epoch: 14, epoch_loss: 0.6423741084603509\n",
      "epoch: 15, epoch_loss: 0.6416428856833284\n",
      "epoch: 16, epoch_loss: 0.6409815494547185\n",
      "epoch: 17, epoch_loss: 0.6403711420973551\n",
      "epoch: 18, epoch_loss: 0.6397964642219937\n",
      "epoch: 19, epoch_loss: 0.6392489180941762\n",
      "995\n",
      "precision: 0.8435374149659864,recall: 0.2505050505050505,f1 score:0.3862928348909657\n",
      "total: 995, correct: 601\n",
      "step:20, test acc: 0.6040201005025125\n",
      "epoch: 20, epoch_loss: 0.6387279755061435\n",
      "epoch: 21, epoch_loss: 0.6382375608604798\n",
      "epoch: 22, epoch_loss: 0.63777908742223\n",
      "epoch: 23, epoch_loss: 0.6373472419801037\n",
      "epoch: 24, epoch_loss: 0.6369297032503738\n",
      "epoch: 25, epoch_loss: 0.6365064106856015\n",
      "epoch: 26, epoch_loss: 0.6360442396291752\n",
      "epoch: 27, epoch_loss: 0.6354832118319482\n",
      "epoch: 28, epoch_loss: 0.6347095200286288\n",
      "epoch: 29, epoch_loss: 0.6335264296466132\n",
      "995\n",
      "precision: 0.8397790055248618,recall: 0.30707070707070705,f1 score:0.44970414201183434\n",
      "total: 995, correct: 623\n",
      "step:30, test acc: 0.6261306532663317\n",
      "epoch: 30, epoch_loss: 0.6318737374138587\n",
      "epoch: 31, epoch_loss: 0.6302399712739531\n",
      "epoch: 32, epoch_loss: 0.6287664342991675\n",
      "epoch: 33, epoch_loss: 0.6272345575270374\n",
      "epoch: 34, epoch_loss: 0.6245982242613723\n",
      "epoch: 35, epoch_loss: 0.6242370328542702\n",
      "epoch: 36, epoch_loss: 0.6196955664051358\n",
      "epoch: 37, epoch_loss: 0.6186388610974211\n",
      "epoch: 38, epoch_loss: 0.6321110312881338\n",
      "epoch: 39, epoch_loss: 0.6202456560741175\n",
      "995\n",
      "precision: 0.85,recall: 0.2404040404040404,f1 score:0.3748031496062992\n",
      "total: 995, correct: 598\n",
      "step:40, test acc: 0.6010050251256281\n",
      "epoch: 40, epoch_loss: 0.6074791394967803\n",
      "epoch: 41, epoch_loss: 0.6046450896771094\n",
      "epoch: 42, epoch_loss: 0.6023203172634557\n",
      "epoch: 43, epoch_loss: 0.6048985781538527\n",
      "epoch: 44, epoch_loss: 0.6134675296311526\n",
      "epoch: 45, epoch_loss: 0.6036160625542971\n",
      "epoch: 46, epoch_loss: 0.6280990449423642\n",
      "epoch: 47, epoch_loss: 0.6028890559148953\n",
      "epoch: 48, epoch_loss: 0.6052594663556089\n",
      "epoch: 49, epoch_loss: 0.5870267073518222\n",
      "995\n",
      "precision: 0.8378378378378378,recall: 0.31313131313131315,f1 score:0.45588235294117646\n",
      "total: 995, correct: 625\n",
      "step:50, test acc: 0.628140703517588\n",
      "epoch: 50, epoch_loss: 0.5822022773555874\n",
      "epoch: 51, epoch_loss: 0.5818889892592872\n",
      "epoch: 52, epoch_loss: 0.568575733244624\n",
      "epoch: 53, epoch_loss: 0.5632528403575477\n",
      "epoch: 54, epoch_loss: 0.552211196582342\n",
      "epoch: 55, epoch_loss: 0.5326101529639201\n",
      "epoch: 56, epoch_loss: 0.5105368904436577\n",
      "epoch: 57, epoch_loss: 0.4947267396138706\n",
      "epoch: 58, epoch_loss: 0.48427594959531045\n",
      "epoch: 59, epoch_loss: 0.47706788766015434\n",
      "995\n",
      "precision: 0.6820809248554913,recall: 0.7151515151515152,f1 score:0.6982248520710059\n",
      "total: 995, correct: 689\n",
      "step:60, test acc: 0.6924623115577889\n",
      "epoch: 60, epoch_loss: 0.46925674371702975\n",
      "epoch: 61, epoch_loss: 0.4613648403346334\n",
      "epoch: 62, epoch_loss: 0.4532432205898246\n",
      "epoch: 63, epoch_loss: 0.44114311388677746\n",
      "epoch: 64, epoch_loss: 0.42914455055780837\n",
      "epoch: 65, epoch_loss: 0.41618599330436734\n",
      "epoch: 66, epoch_loss: 0.40039641230376727\n",
      "epoch: 67, epoch_loss: 0.3850759798718482\n",
      "epoch: 68, epoch_loss: 0.3701894284626053\n",
      "epoch: 69, epoch_loss: 0.3557769157222866\n",
      "995\n",
      "precision: 0.737603305785124,recall: 0.7212121212121212,f1 score:0.7293156281920328\n",
      "total: 995, correct: 730\n",
      "step:70, test acc: 0.7336683417085427\n",
      "epoch: 70, epoch_loss: 0.34215147106098553\n",
      "epoch: 71, epoch_loss: 0.3290670842854018\n",
      "epoch: 72, epoch_loss: 0.3170941401695468\n",
      "epoch: 73, epoch_loss: 0.30634785453273666\n",
      "epoch: 74, epoch_loss: 0.2957130243995345\n",
      "epoch: 75, epoch_loss: 0.28563836535432496\n",
      "epoch: 76, epoch_loss: 0.27568357029731333\n",
      "epoch: 77, epoch_loss: 0.2667246138721807\n",
      "epoch: 78, epoch_loss: 0.2577268216874182\n",
      "epoch: 79, epoch_loss: 0.24907262725211501\n",
      "995\n",
      "precision: 0.7869565217391304,recall: 0.7313131313131314,f1 score:0.7581151832460733\n",
      "total: 995, correct: 764\n",
      "step:80, test acc: 0.7678391959798995\n",
      "epoch: 80, epoch_loss: 0.24057111238798326\n",
      "epoch: 81, epoch_loss: 0.23244428911672016\n",
      "epoch: 82, epoch_loss: 0.22482027484174447\n",
      "epoch: 83, epoch_loss: 0.21756078252165587\n",
      "epoch: 84, epoch_loss: 0.2106523001777757\n",
      "epoch: 85, epoch_loss: 0.20419027488358651\n",
      "epoch: 86, epoch_loss: 0.19794195594963748\n",
      "epoch: 87, epoch_loss: 0.19122286630455163\n",
      "epoch: 88, epoch_loss: 0.18511908384635276\n",
      "epoch: 89, epoch_loss: 0.17936978798449243\n",
      "995\n",
      "precision: 0.810752688172043,recall: 0.7616161616161616,f1 score:0.7854166666666667\n",
      "total: 995, correct: 789\n",
      "step:90, test acc: 0.792964824120603\n",
      "epoch: 90, epoch_loss: 0.1741399385163055\n",
      "epoch: 91, epoch_loss: 0.16854892314709338\n",
      "epoch: 92, epoch_loss: 0.16225456996625642\n",
      "epoch: 93, epoch_loss: 0.15743548084575287\n",
      "epoch: 94, epoch_loss: 0.15208837489799126\n",
      "epoch: 95, epoch_loss: 0.14735410643607072\n",
      "epoch: 96, epoch_loss: 0.14325163210278113\n",
      "epoch: 97, epoch_loss: 0.13929512812099915\n",
      "epoch: 98, epoch_loss: 0.13442336295273705\n",
      "epoch: 99, epoch_loss: 0.1308014617471146\n",
      "995\n",
      "precision: 0.8333333333333334,recall: 0.7777777777777778,f1 score:0.8045977011494253\n",
      "total: 995, correct: 808\n",
      "step:100, test acc: 0.8120603015075377\n",
      "epoch: 100, epoch_loss: 0.1265335058249354\n",
      "epoch: 101, epoch_loss: 0.12175886066841711\n",
      "epoch: 102, epoch_loss: 0.11794148074059757\n",
      "epoch: 103, epoch_loss: 0.11478781225191768\n",
      "epoch: 104, epoch_loss: 0.11043663127059788\n",
      "epoch: 105, epoch_loss: 0.10698917786433934\n",
      "epoch: 106, epoch_loss: 0.10399785110298096\n",
      "epoch: 107, epoch_loss: 0.10095823310648452\n",
      "epoch: 108, epoch_loss: 0.09831744736617373\n",
      "epoch: 109, epoch_loss: 0.09622142090753387\n",
      "995\n",
      "precision: 0.849015317286652,recall: 0.7838383838383839,f1 score:0.8151260504201681\n",
      "total: 995, correct: 819\n",
      "step:110, test acc: 0.8231155778894472\n",
      "epoch: 110, epoch_loss: 0.09415730382747871\n",
      "epoch: 111, epoch_loss: 0.08854236337148241\n",
      "epoch: 112, epoch_loss: 0.08640093528809621\n",
      "epoch: 113, epoch_loss: 0.08484812083932543\n",
      "epoch: 114, epoch_loss: 0.08216065135096356\n",
      "epoch: 115, epoch_loss: 0.08005372721484232\n",
      "epoch: 116, epoch_loss: 0.07716369985049124\n",
      "epoch: 117, epoch_loss: 0.07454175301587458\n",
      "epoch: 118, epoch_loss: 0.07244339913795494\n",
      "epoch: 119, epoch_loss: 0.0721668889906091\n",
      "995\n",
      "precision: 0.849438202247191,recall: 0.7636363636363637,f1 score:0.8042553191489361\n",
      "total: 995, correct: 811\n",
      "step:120, test acc: 0.8150753768844221\n",
      "epoch: 120, epoch_loss: 0.06935384393608857\n",
      "epoch: 121, epoch_loss: 0.06513310900002821\n",
      "epoch: 122, epoch_loss: 0.06377182329822446\n",
      "epoch: 123, epoch_loss: 0.06400257396444525\n",
      "epoch: 124, epoch_loss: 0.060234436296771485\n",
      "epoch: 125, epoch_loss: 0.05744927478026074\n",
      "epoch: 126, epoch_loss: 0.05537157705904999\n",
      "epoch: 127, epoch_loss: 0.05784681290132074\n",
      "epoch: 128, epoch_loss: 0.05169475964747395\n",
      "epoch: 129, epoch_loss: 0.050210570026176286\n",
      "995\n",
      "precision: 0.8590604026845637,recall: 0.7757575757575758,f1 score:0.8152866242038216\n",
      "total: 995, correct: 821\n",
      "step:130, test acc: 0.8251256281407036\n",
      "epoch: 130, epoch_loss: 0.053022638646584914\n",
      "epoch: 131, epoch_loss: 0.048385271056206366\n",
      "epoch: 132, epoch_loss: 0.04914001743101173\n",
      "epoch: 133, epoch_loss: 0.048286373647973196\n",
      "epoch: 134, epoch_loss: 0.04976626338782845\n",
      "epoch: 135, epoch_loss: 0.04477938472027682\n",
      "epoch: 136, epoch_loss: 0.041389745335603495\n",
      "epoch: 137, epoch_loss: 0.04321367341922628\n",
      "epoch: 138, epoch_loss: 0.04240600322069171\n",
      "epoch: 139, epoch_loss: 0.043678162036994886\n",
      "995\n",
      "precision: 0.875,recall: 0.7777777777777778,f1 score:0.823529411764706\n",
      "total: 995, correct: 830\n",
      "step:140, test acc: 0.8341708542713567\n",
      "epoch: 140, epoch_loss: 0.03914954165297583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 141, epoch_loss: 0.03571099317232563\n",
      "epoch: 142, epoch_loss: 0.035548185626896184\n",
      "epoch: 143, epoch_loss: 0.03618466306087334\n",
      "epoch: 144, epoch_loss: 0.03310610615037049\n",
      "epoch: 145, epoch_loss: 0.03180138385723444\n",
      "epoch: 146, epoch_loss: 0.03266106594555541\n",
      "epoch: 147, epoch_loss: 0.030579110835534856\n",
      "epoch: 148, epoch_loss: 0.029915282092956488\n",
      "epoch: 149, epoch_loss: 0.03871987210586667\n",
      "995\n",
      "precision: 0.8741258741258742,recall: 0.7575757575757576,f1 score:0.8116883116883118\n",
      "total: 995, correct: 821\n",
      "step:150, test acc: 0.8251256281407036\n",
      "epoch: 150, epoch_loss: 0.029052119996379484\n",
      "epoch: 151, epoch_loss: 0.026217932820710582\n",
      "epoch: 152, epoch_loss: 0.027836182598613483\n",
      "epoch: 153, epoch_loss: 0.026595752249724675\n",
      "epoch: 154, epoch_loss: 0.026704364464077396\n",
      "epoch: 155, epoch_loss: 0.025776489739565506\n",
      "epoch: 156, epoch_loss: 0.022817340016019406\n",
      "epoch: 157, epoch_loss: 0.020601378919243095\n",
      "epoch: 158, epoch_loss: 0.028508681979004767\n",
      "epoch: 159, epoch_loss: 0.023205565824253403\n",
      "995\n",
      "precision: 0.872093023255814,recall: 0.7575757575757576,f1 score:0.8108108108108109\n",
      "total: 995, correct: 820\n",
      "step:160, test acc: 0.8241206030150754\n",
      "epoch: 160, epoch_loss: 0.024360854291481916\n",
      "epoch: 161, epoch_loss: 0.0240559816690117\n",
      "epoch: 162, epoch_loss: 0.021136736828686598\n",
      "epoch: 163, epoch_loss: 0.0194759940909369\n",
      "epoch: 164, epoch_loss: 0.016971552384620423\n",
      "epoch: 165, epoch_loss: 0.016093783776989508\n",
      "epoch: 166, epoch_loss: 0.015908519657891997\n",
      "epoch: 167, epoch_loss: 0.018541888950738248\n",
      "epoch: 168, epoch_loss: 0.022191080192097583\n",
      "epoch: 169, epoch_loss: 0.01797573136060124\n",
      "995\n",
      "precision: 0.8805620608899297,recall: 0.7595959595959596,f1 score:0.8156182212581343\n",
      "total: 995, correct: 825\n",
      "step:170, test acc: 0.8291457286432161\n",
      "epoch: 170, epoch_loss: 0.0198936268381608\n",
      "epoch: 171, epoch_loss: 0.019984118817726156\n",
      "epoch: 172, epoch_loss: 0.023961666819585097\n",
      "epoch: 173, epoch_loss: 0.01836910806836311\n",
      "epoch: 174, epoch_loss: 0.015833700008216694\n",
      "epoch: 175, epoch_loss: 0.012187592484396194\n",
      "epoch: 176, epoch_loss: 0.009481532407182035\n",
      "epoch: 177, epoch_loss: 0.008943170061034128\n",
      "epoch: 178, epoch_loss: 0.0137018277135412\n",
      "epoch: 179, epoch_loss: 0.01458036745530377\n",
      "995\n",
      "precision: 0.8630434782608696,recall: 0.802020202020202,f1 score:0.831413612565445\n",
      "total: 995, correct: 834\n",
      "step:180, test acc: 0.8381909547738694\n",
      "epoch: 180, epoch_loss: 0.013904504178578348\n",
      "epoch: 181, epoch_loss: 0.018472620528479367\n",
      "epoch: 182, epoch_loss: 0.01730147932153643\n",
      "epoch: 183, epoch_loss: 0.016531402466793087\n",
      "epoch: 184, epoch_loss: 0.014256371672447655\n",
      "epoch: 185, epoch_loss: 0.01262683843668947\n",
      "epoch: 186, epoch_loss: 0.00848411597100269\n",
      "epoch: 187, epoch_loss: 0.006639544528675397\n",
      "epoch: 188, epoch_loss: 0.005416306895859975\n",
      "epoch: 189, epoch_loss: 0.0046643035790380535\n",
      "995\n",
      "precision: 0.8862559241706162,recall: 0.7555555555555555,f1 score:0.8157033805888768\n",
      "total: 995, correct: 826\n",
      "step:190, test acc: 0.8301507537688442\n",
      "epoch: 190, epoch_loss: 0.004754192739104231\n",
      "epoch: 191, epoch_loss: 0.004268018570104518\n",
      "epoch: 192, epoch_loss: 0.003706816801340463\n",
      "epoch: 193, epoch_loss: 0.003249132166427794\n",
      "epoch: 194, epoch_loss: 0.0029692847974585605\n",
      "epoch: 195, epoch_loss: 0.002774088008047635\n",
      "epoch: 196, epoch_loss: 0.002596113525564651\n",
      "epoch: 197, epoch_loss: 0.002397605899522958\n",
      "epoch: 198, epoch_loss: 0.0022145973080033086\n",
      "epoch: 199, epoch_loss: 0.002063947154810697\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(compare_regex_model.parameters(), lr=0.1)\n",
    "batch_size = 256\n",
    "\n",
    "batch_num = int(len(lines1_seq2idx)/batch_size)\n",
    "for epoch in range(200):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    for batch in range(batch_num):\n",
    "        compare_regex_model.zero_grad()\n",
    "        lines1_batch = lines1_seq2idx[batch * batch_size:(batch+1) * batch_size]\n",
    "        lines2_batch = lines2_seq2idx[batch * batch_size:(batch+1) * batch_size]\n",
    "        lines1_batch_lengths = torch.tensor([torch.max(lines1_batch[i].data.nonzero()+1) for i in range(len(lines1_batch))]).cuda()\n",
    "        lines2_batch_lengths = torch.tensor([torch.max(lines2_batch[i].data.nonzero()+1) for i in range(len(lines2_batch))]).cuda()\n",
    "        tag_score = compare_regex_model(batch_size, lines1_batch, lines2_batch, lines1_batch_lengths.tolist(), lines2_batch_lengths.tolist())\n",
    "        targets_batches = targets_idx[batch * batch_size:(batch+1) * batch_size]\n",
    "        loss = loss_function(tag_score.squeeze(1).squeeze(1), targets_batches[:,1])\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            test_acc = evaluate_test(compare_regex_model, test_input1, test_input2, test_targets)\n",
    "            print('step:{}, test acc: {}'.format(epoch, test_acc))\n",
    "    \n",
    "    if test_acc == 1.0:\n",
    "        break\n",
    "    print('epoch: {}, epoch_loss: {}'.format(epoch,epoch_loss/batch_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5297\n",
      "precision: 0.9775280898876404,recall: 0.9642474079370754,f1 score:0.9708423326133908\n",
      "total: 5297, correct: 5135\n",
      "test acc: 0.9694166509344913\n",
      "epoch: 199, epoch_loss: 0.024494519908640443\n"
     ]
    }
   ],
   "source": [
    "batch_num = int(len(lines1_seq2idx)/batch_size)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_acc = evaluate_test(compare_regex_model, test_input1, test_input2, test_targets)\n",
    "    print('test acc: {}'.format(test_acc))\n",
    "    \n",
    "    print('epoch: {}, epoch_loss: {}'.format(epoch,epoch_loss/batch_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/rl/lib/python3.5/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type compare_regex. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(compare_regex_model, './compare_regex_model_share2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_regex_model = torch.load('./compare_regex_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single input test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = ['( ( <M0> ) & ( [ <LET> ] ) ) . * ( [ <CAP> ] ) . *']\n",
    "predict = ['( <M0> ) . * ( ( [ <CAP> ] ) & ( [ <CAP> ] ) ) . *']\n",
    "target = [0]\n",
    "gold_input, predict_input, target_input = make_input_seq(gold, predict, target)\n",
    "gold_len = torch.tensor([torch.max(gold_input[0].data.nonzero()+1)])\n",
    "predict_len = torch.tensor([torch.max(predict_input[0].data.nonzero()+1)])\n",
    "print(gold_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vocab = dict(map(reversed, vocab.items()))\n",
    "print(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([new_vocab[j] for j in [i for i in gold_input.tolist()[0]]]).replace('<pad>','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "with torch.no_grad():\n",
    "    score = compare_regex_model(1, gold_input, predict_input, [gold_len], [predict_len])\n",
    "    print(math.exp(score[0][0]))\n",
    "    print(math.exp(score[0][1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../pair_data/test.txt','r')\n",
    "\n",
    "\n",
    "total_set = set()\n",
    "lines1 = list()\n",
    "lines2 = list()\n",
    "targets = list()\n",
    "\n",
    "count = 0\n",
    "for line in f.read().splitlines():\n",
    "    count += 1\n",
    "    total_set.add(line)\n",
    "    splitted = line.split('\\t')\n",
    "#     total_set.add('{}\\t{}\\t{}'.format(splitted[1],splitted[0],splitted[2]))\n",
    "print(count)\n",
    "\n",
    "count = 0\n",
    "for line in total_set:\n",
    "    count += 1\n",
    "    splitted = line.split('\\t')\n",
    "    lines1.append(splitted[0])\n",
    "    lines2.append(splitted[1])\n",
    "    targets.append(splitted[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input1, test_input2, test_targets = make_input_seq(lines1, lines2, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "        print('test acc: {}'.format(evaluate_test(compare_regex_model, test_input1, test_input2,  test_targets)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
